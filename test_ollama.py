#!/usr/bin/env python3
"""
Ollamaæ¥ç¶šãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""
import asyncio
import httpx
import os

# ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒç”¨ã®è¨­å®š
os.environ["OLLAMA_LIGHT_HOST"] = "localhost"
os.environ["OLLAMA_LIGHT_PORT"] = "11433"
os.environ["OLLAMA_MAIN_HOST"] = "localhost"  
os.environ["OLLAMA_MAIN_PORT"] = "11434"

# ã‚µãƒ¼ãƒ“ã‚¹ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from app.services.ollama_service import OllamaService


async def test_ollama():
    service = OllamaService()
    
    print("ğŸ” Ollamaæ¥ç¶šãƒ†ã‚¹ãƒˆ")
    print(f"Light URL: {service.light_base_url}")
    print(f"Main URL: {service.main_base_url}")
    print()
    
    # æ¥ç¶šãƒ†ã‚¹ãƒˆ
    print("1ï¸âƒ£ æ¥ç¶šç¢ºèª...")
    connection_status = await service.test_connection()
    print(f"  è»½é‡LLM: {'âœ…' if connection_status['light_llm'] else 'âŒ'}")
    print(f"  ãƒ¡ã‚¤ãƒ³LLM: {'âœ…' if connection_status['main_llm'] else 'âŒ'}")
    print()
    
    # æ„å›³è§£æãƒ†ã‚¹ãƒˆ
    if connection_status['light_llm']:
        print("2ï¸âƒ£ æ„å›³è§£æãƒ†ã‚¹ãƒˆ...")
        message = "æœ­å¹Œã®ã‚¨ãƒ³ãƒˆãƒª1å·¥ç¨‹ãŒé…å»¶ã—ã¦ã„ã¾ã™ã€‚å¯¾å¿œç­–ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚"
        intent = await service.analyze_intent(message)
        print(f"  å…¥åŠ›: {message}")
        print(f"  æ„å›³ã‚¿ã‚¤ãƒ—: {intent.get('intent_type')}")
        print(f"  ç·Šæ€¥åº¦: {intent.get('urgency')}")
        print(f"  ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£: {intent.get('entities')}")
        print()
    
    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç”Ÿæˆãƒ†ã‚¹ãƒˆ
    if connection_status['main_llm'] and intent:
        print("3ï¸âƒ£ ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç”Ÿæˆãƒ†ã‚¹ãƒˆ...")
        response = await service.generate_response(message, intent)
        print(f"  ãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼ˆæœ€åˆã®200æ–‡å­—ï¼‰:")
        print(f"  {response[:200]}...")


if __name__ == "__main__":
    asyncio.run(test_ollama())