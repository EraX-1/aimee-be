from fastapi import APIRouter, HTTPException
from datetime import datetime
import random
import uuid

from app.schemas.requests.chat import ChatMessageRequest
from app.schemas.responses.chat import ChatResponse, Suggestion, AllocationChange, Impact
from app.core.logging import app_logger

router = APIRouter()


def generate_suggestion(message: str, context: dict) -> Suggestion:
    """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«åŸºã¥ã„ã¦é…ç½®ææ¡ˆã‚’ç”Ÿæˆï¼ˆãƒ¢ãƒƒã‚¯ï¼‰"""
    
    # ãƒ‡ãƒ¢ç”¨ã®ææ¡ˆãƒ‘ã‚¿ãƒ¼ãƒ³
    suggestions = [
        {
            "changes": [
                {"from": "ç››å²¡", "to": "æœ­å¹Œ", "process": "ã‚¨ãƒ³ãƒˆãƒª1", "count": 3},
                {"from": "å“å·", "to": "æœ­å¹Œ", "process": "ã‚¨ãƒ³ãƒˆãƒª1", "count": 2},
                {"from": "è¥¿æ¢…ç”°", "to": "æœ­å¹Œ", "process": "ã‚¨ãƒ³ãƒˆãƒª1", "count": 1}
            ],
            "impact": {
                "productivity": "+25%",
                "delay": "-30åˆ†",
                "quality": "ç¶­æŒ"
            },
            "reason": "éå»ã®é¡ä¼¼ã‚±ãƒ¼ã‚¹ã§ã¯ã€ã“ã®é…ç½®ã«ã‚ˆã‚Š95%ã®ç¢ºç‡ã§é…å»¶è§£æ¶ˆ"
        },
        {
            "changes": [
                {"from": "æ²–ç¸„", "to": "ç››å²¡", "process": "è£œæ­£", "count": 2},
                {"from": "ä½ä¸–ä¿", "to": "ç››å²¡", "process": "è£œæ­£", "count": 1}
            ],
            "impact": {
                "productivity": "+15%",
                "delay": "-20åˆ†",
                "quality": "+2%"
            },
            "reason": "è£œæ­£å·¥ç¨‹ã®çµŒé¨“è€…ã‚’é›†ä¸­é…ç½®ã™ã‚‹ã“ã¨ã§å“è³ªå‘ä¸ŠãŒæœŸå¾…ã§ãã¾ã™"
        },
        {
            "changes": [
                {"from": "æœ¬ç”ºæ±", "to": "å“å·", "process": "ã‚¨ãƒ³ãƒˆãƒª2", "count": 4},
                {"from": "å’Œæ­Œå±±", "to": "å“å·", "process": "ã‚¨ãƒ³ãƒˆãƒª2", "count": 2}
            ],
            "impact": {
                "productivity": "+30%",
                "delay": "-40åˆ†",
                "quality": "ç¶­æŒ"
            },
            "reason": "å“å·æ‹ ç‚¹ã®å‡¦ç†èƒ½åŠ›ã‚’æœ€å¤§åŒ–ã—ã€å…¨ä½“ã®åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã¾ã™"
        }
    ]
    
    # ãƒ©ãƒ³ãƒ€ãƒ ã«ææ¡ˆã‚’é¸æŠï¼ˆå®Ÿéš›ã¯AI/MLãƒ¢ãƒ‡ãƒ«ã§ç”Ÿæˆï¼‰
    selected = random.choice(suggestions)
    
    return Suggestion(
        id=f"SGT{datetime.now().year}-{str(uuid.uuid4())[:8].upper()}",
        changes=[AllocationChange(**change) for change in selected["changes"]],
        impact=Impact(**selected["impact"]),
        reason=selected["reason"],
        confidence_score=random.uniform(0.85, 0.98)
    )


@router.post("/message", response_model=ChatResponse, summary="ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡")
async def send_chat_message(request: ChatMessageRequest):
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å—ã‘å–ã‚Šã€AIé…ç½®èª¿æ•´ã®ææ¡ˆã‚’è¿”ã—ã¾ã™ã€‚
    çµ±åˆLLMã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½¿ç”¨ã—ã¦å®Ÿéš›ã®AIå‡¦ç†ã‚’è¡Œã„ã¾ã™ã€‚
    """
    app_logger.info(f"Received chat message: {request.message}")

    from app.services.integrated_llm_service import IntegratedLLMService
    from app.db.session import get_db

    try:
        # çµ±åˆLLMã‚µãƒ¼ãƒ“ã‚¹ã§AIå‡¦ç†
        llm_service = IntegratedLLMService()

        # éåŒæœŸDBæ¥ç¶šã‚’å–å¾—
        async for db in get_db():
            result = await llm_service.process_message(
                message=request.message,
                context=request.context,
                db=db,
                detail=False
            )

            # å¿œç­”ã‚’æ•´å½¢
            response_text = result.get("response", "å¿œç­”ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸ")
            suggestion_data = result.get("suggestion")

            # ææ¡ˆãŒã‚ã‚Œã°å¤‰æ›
            suggestion = None
            if suggestion_data:
                suggestion = Suggestion(
                    id=suggestion_data.get("id", f"SGT{datetime.now().year}-{str(uuid.uuid4())[:8].upper()}"),
                    changes=[AllocationChange(**c) for c in suggestion_data.get("changes", [])],
                    impact=Impact(**suggestion_data.get("impact", {})),
                    reason=suggestion_data.get("reason", ""),
                    confidence_score=suggestion_data.get("confidence_score", 0.85)
                )

            return ChatResponse(
                response=response_text,
                suggestion=suggestion,
                timestamp=datetime.now()
            )

    except Exception as e:
        app_logger.error(f"Chat message processing error: {e}")

        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ã‚·ãƒ³ãƒ—ãƒ«ãªå¿œç­”ã‚’è¿”ã™
        response_text = f"""
äº†è§£ã—ã¾ã—ãŸã€‚ã€Œ{request.message}ã€ã«ã¤ã„ã¦åˆ†æã—ã¾ã™ã€‚

âš ï¸ ç¾åœ¨ã€AIå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ä¸­ã§ã™ã€‚
ç°¡æ˜“ãƒ¢ãƒ¼ãƒ‰ã§å¿œç­”ã—ã¦ã„ã¾ã™ã€‚

ğŸ“Š **ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å—ä¿¡**: ç¢ºèªã—ã¾ã—ãŸ
ğŸ”„ **ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹**: èµ·å‹•å‡¦ç†ä¸­

ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„ã€‚
"""

        return ChatResponse(
            response=response_text,
            suggestion=None,
            timestamp=datetime.now()
        )


@router.get("/history", summary="ãƒãƒ£ãƒƒãƒˆå±¥æ­´å–å¾—")
async def get_chat_history(
    limit: int = 10,
    offset: int = 0
):
    """
    ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’å–å¾—ã—ã¾ã™ã€‚
    """
    # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å–å¾—
    app_logger.info(f"Getting chat history: limit={limit}, offset={offset}")
    
    history = [
        {
            "role": "user",
            "content": "æœ­å¹Œã®ã‚¨ãƒ³ãƒˆãƒª1å·¥ç¨‹ãŒé…å»¶ã—ã¦ã„ã¾ã™",
            "timestamp": "2024-01-15T10:25:00"
        },
        {
            "role": "assistant",
            "content": "æ‰¿çŸ¥ã—ã¾ã—ãŸã€‚æœ­å¹Œã®ã‚¨ãƒ³ãƒˆãƒª1å·¥ç¨‹ã®é…å»¶ã«ã¤ã„ã¦åˆ†æã—ã€æœ€é©ãªé…ç½®ã‚’ææ¡ˆã—ã¾ã™ã€‚",
            "timestamp": "2024-01-15T10:25:30"
        }
    ]
    
    return {
        "history": history,
        "total": len(history),
        "limit": limit,
        "offset": offset
    }