"""
Ollama LLMã‚µãƒ¼ãƒ“ã‚¹
"""
import httpx
import json
from typing import Dict, Any, Optional
from app.core.config import settings
from app.core.logging import app_logger


class OllamaService:
    """Ollamaã¨ã®é€šä¿¡ã‚’ç®¡ç†ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹"""
    
    def __init__(self):
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã‚€ï¼ˆDockerã‚³ãƒ³ãƒ†ãƒŠå†…ã§ã¯ã‚µãƒ¼ãƒ“ã‚¹åã‚’ä½¿ç”¨ï¼‰
        light_host = settings.OLLAMA_LIGHT_HOST
        light_port = settings.OLLAMA_LIGHT_PORT
        main_host = settings.OLLAMA_MAIN_HOST
        main_port = settings.OLLAMA_MAIN_PORT
        
        self.light_base_url = f"http://{light_host}:{light_port}"
        self.main_base_url = f"http://{main_host}:{main_port}"
        self.timeout = httpx.Timeout(120.0)
        
        app_logger.info(f"Ollama URLs - Light: {self.light_base_url}, Main: {self.main_base_url}")
        
    async def analyze_intent(self, message: str) -> Dict[str, Any]:
        """
        è»½é‡LLMã§æ„å›³è§£æã‚’è¡Œã†
        
        Args:
            message: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            
        Returns:
            æ„å›³è§£æçµæœ
        """
        prompt = f"""ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰æ„å›³ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚

ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {message}

JSONå½¢å¼ã§å›ç­”ï¼ˆJSONã®ã¿ã€èª¬æ˜ä¸è¦ï¼‰:
{{
  "intent_type": "é©åˆ‡ãªã‚¿ã‚¤ãƒ—ã‚’é¸æŠ",
  "urgency": "high",
  "requires_action": true,
  "entities": {{
    "location": "æ‹ ç‚¹å",
    "process": "å·¥ç¨‹å",
    "issue_type": "å•é¡Œã®ç¨®é¡"
  }}
}}

intent_typeã¯ä»¥ä¸‹ã‹ã‚‰æœ€ã‚‚é©åˆ‡ãªã‚‚ã®ã‚’1ã¤ã ã‘é¸æŠ:
- deadline_optimization: ç´æœŸã€å‡¦ç†å®Œäº†æ™‚åˆ»ã€20åˆ†å‰ãªã©ã®è¨€åŠãŒã‚ã‚‹å ´åˆ
- completion_time_prediction: ã€Œä½•æ™‚ã«çµ‚äº†ã€ã€Œã„ã¤å®Œäº†ã€ãªã©ã®æ™‚åˆ»äºˆæ¸¬ã®è³ªå•
- delay_risk_detection: ã€Œé…å»¶ã€ã€Œè¦‹è¾¼ã¿ã€ã€Œãƒªã‚¹ã‚¯ã€ãªã©ã®æ¤œå‡ºè¦æ±‚
- impact_analysis: ã€Œå½±éŸ¿ã€ã€Œå¤§ä¸ˆå¤«ã€ãªã©ã®å½±éŸ¿åˆ†æè¦æ±‚
- cross_business_transfer: ã€ŒéSSã‹ã‚‰ã€ã€Œæ¥­å‹™é–“ã€ãªã©ã®æ¥­å‹™é–“ç§»å‹•
- process_optimization: ã€Œå„å·¥ç¨‹ä½•äººã€ãªã©ã®å·¥ç¨‹åˆ¥æœ€é©åŒ–
- delay_resolution: ä¸Šè¨˜ä»¥å¤–ã®é…å»¶è§£æ¶ˆãƒ»äººå“¡ä¸è¶³å¯¾å¿œ
- status_check: çŠ¶æ³ç¢ºèªã®ã¿
- general_inquiry: ä¸€èˆ¬è³ªå•"""
        
        try:
            async with httpx.AsyncClient(timeout=self.timeout) as client:
                response = await client.post(
                    f"{self.light_base_url}/api/generate",
                    json={
                        "model": settings.INTENT_MODEL,
                        "prompt": prompt,
                        "stream": False,
                        "options": {
                            "temperature": 0.1,
                            "num_predict": 512,
                            "top_k": 10,
                            "top_p": 0.9
                        }
                    }
                )
                response.raise_for_status()
                
            result = response.json()
            app_logger.info(f"Raw LLM response: {result}")
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰JSONéƒ¨åˆ†ã‚’æŠ½å‡º
            llm_response = result.get("response", "{}")
            
            # JSONæ–‡å­—åˆ—ã‚’ãƒ‘ãƒ¼ã‚¹
            try:
                parsed_intent = json.loads(llm_response)

                # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã§intent_typeã‚’ä¸Šæ›¸ãï¼ˆç²¾åº¦å‘ä¸Šã®ãŸã‚ï¼‰
                if any(kw in message for kw in ['ä½•æ™‚ã«çµ‚äº†', 'å®Œäº†æ™‚åˆ»', 'çµ‚ã‚ã‚‹æƒ³å®š', 'ä½•æ™‚ã«å®Œäº†']):
                    parsed_intent['intent_type'] = 'completion_time_prediction'
                elif any(kw in message for kw in ['é…å»¶ãŒç™ºç”Ÿ', 'é…å»¶ã™ã‚‹è¦‹è¾¼ã¿', 'ãƒªã‚¹ã‚¯', 'é…ã‚Œ']):
                    parsed_intent['intent_type'] = 'delay_risk_detection'
                elif any(kw in message for kw in ['å½±éŸ¿', 'å¤§ä¸ˆå¤«', 'ç§»å‹•å…ƒ']):
                    parsed_intent['intent_type'] = 'impact_analysis'
                elif any(kw in message for kw in ['éSSã‹ã‚‰', 'æ¥­å‹™é–“', 'éSS']):
                    parsed_intent['intent_type'] = 'cross_business_transfer'
                elif any(kw in message for kw in ['å„å·¥ç¨‹ä½•äºº', 'å·¥ç¨‹åˆ¥', 'å·¥ç¨‹ã”ã¨']):
                    parsed_intent['intent_type'] = 'process_optimization'
                elif any(kw in message for kw in ['ç´æœŸ', '20åˆ†å‰', 'å‡¦ç†å®Œäº†']):
                    parsed_intent['intent_type'] = 'deadline_optimization'

                # æ­£è¦è¡¨ç¾ã§æ‹ ç‚¹åãƒ»å·¥ç¨‹åã‚’å†æŠ½å‡ºï¼ˆLLMãŒé–“é•ãˆã‚‹ãŸã‚ï¼‰
                locations = ['æœ­å¹Œ', 'å“å·', 'ä½ä¸–ä¿', 'æœ¬ç”ºæ±', 'è¥¿æ¢…ç”°', 'æ²–ç¸„', 'å’Œæ­Œå±±', 'ç››å²¡']
                for loc in locations:
                    if loc in message:
                        parsed_intent['entities']['location'] = loc
                        break

                processes_map = {
                    'ã‚¨ãƒ³ãƒˆãƒª1': 'ã‚¨ãƒ³ãƒˆãƒª1', 'ã‚¨ãƒ³ãƒˆãƒªãƒ¼1': 'ã‚¨ãƒ³ãƒˆãƒª1',
                    'ã‚¨ãƒ³ãƒˆãƒª2': 'ã‚¨ãƒ³ãƒˆãƒª2', 'ã‚¨ãƒ³ãƒˆãƒªãƒ¼2': 'ã‚¨ãƒ³ãƒˆãƒª2',
                    'è£œæ­£': 'è£œæ­£', 'SVè£œæ­£': 'SVè£œæ­£', 'ç›®æ¤œ': 'ç›®æ¤œ'
                }
                for key, value in processes_map.items():
                    if key in message:
                        parsed_intent['entities']['process'] = value
                        break

                # æ¥­å‹™åã‚’æŠ½å‡º
                if 'SS' in message and 'éSS' not in message:
                    parsed_intent['entities']['business'] = 'SS'
                elif 'éSS' in message:
                    parsed_intent['entities']['business'] = 'éSS'
                elif 'ã‚ã¯ã' in message:
                    parsed_intent['entities']['business'] = 'ã‚ã¯ã'
                elif 'é©å¾´' in message or 'é©ç”¨å¾´å' in message:
                    parsed_intent['entities']['business'] = 'é©å¾´'

                app_logger.info(f"Parsed intent (ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ¤å®šå¾Œ): {parsed_intent}")
                return parsed_intent
            except json.JSONDecodeError:
                app_logger.error(f"Failed to parse JSON from LLM response: {llm_response}")
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®æ„å›³ã‚’è¿”ã™
                return {
                    "intent_type": "general_inquiry",
                    "urgency": "medium",
                    "requires_action": False,
                    "entities": {}
                }
                
        except Exception as e:
            app_logger.error(f"Error in intent analysis: {str(e)}")
            return {
                "intent_type": "error",
                "urgency": "low",
                "requires_action": False,
                "entities": {},
                "error": str(e)
            }
    
    async def generate_response(
        self,
        message: str,
        intent: Dict[str, Any],
        context: Optional[Dict[str, Any]] = None,
        db_data: Optional[Dict[str, Any]] = None,
        suggestion: Optional[Dict[str, Any]] = None,
        rag_results: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        ãƒ¡ã‚¤ãƒ³LLMã§è©³ç´°ãªå¿œç­”ã‚’ç”Ÿæˆ
        
        Args:
            message: å…ƒã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            intent: æ„å›³è§£æçµæœ
            context: è¿½åŠ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±
            db_data: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å–å¾—ãƒ‡ãƒ¼ã‚¿
            suggestion: ç”Ÿæˆã•ã‚ŒãŸææ¡ˆ
            
        Returns:
            ç”Ÿæˆã•ã‚ŒãŸå¿œç­”ãƒ†ã‚­ã‚¹ãƒˆ
        """
        intent_type = intent.get('intent_type')
        entities = intent.get('entities', {})
        location = entities.get('location', 'è©²å½“æ‹ ç‚¹')
        process = entities.get('process', 'è©²å½“å·¥ç¨‹')
        business = entities.get('business', '')
        issue_type = entities.get('issue_type', 'å•é¡Œ')

        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±ã®ã‚µãƒãƒªãƒ¼ä½œæˆ
        db_summary = self._create_db_summary(db_data) if db_data else ""
        suggestion_summary = self._create_suggestion_summary(suggestion) if suggestion else ""
        rag_summary = self._create_rag_summary(rag_results) if rag_results else ""

        # å…¥åŠ›ã®æŠ½è±¡åº¦åˆ¤å®š
        is_abstract_input = self._is_abstract_input(message)

        # intent_typeåˆ¥ã®ç‰¹åˆ¥å‡¦ç†
        if intent_type == "completion_time_prediction":
            return await self._generate_completion_time_response(message, db_data, rag_results)
        elif intent_type == "delay_risk_detection":
            return await self._generate_delay_risk_response(message, db_data, rag_results)
        elif intent_type == "impact_analysis":
            return await self._generate_impact_analysis_response(message, db_data, suggestion, rag_results)
        elif intent_type == "cross_business_transfer":
            return await self._generate_cross_business_transfer_response(message, db_data, rag_results)
        elif intent_type == "process_optimization":
            return await self._generate_process_optimization_response(message, db_data, rag_results)
        
        if is_abstract_input:
            prompt = f"""å…¥åŠ›ã€Œ{message}ã€ã§ã¯æƒ…å ±ä¸è¶³ã§ã™ã€‚ä»¥ä¸‹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼š
- æ‹ ç‚¹åï¼ˆä¾‹ï¼šæœ­å¹Œã€æ±äº¬ã€å¤§é˜ªï¼‰
- å·¥ç¨‹åï¼ˆä¾‹ï¼šã‚¨ãƒ³ãƒˆãƒª1ã€è£œæ­£ã€SVè£œæ­£ï¼‰
- å•é¡Œå†…å®¹ï¼ˆä¾‹ï¼šé…å»¶ã€äººå“¡ä¸è¶³ï¼‰"""
        else:
            # DBãƒ‡ãƒ¼ã‚¿ã¨ã‚·ã‚¹ãƒ†ãƒ ææ¡ˆãŒã‚ã‚‹å ´åˆã®ã¿è©³ç´°ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            if db_summary and db_summary != "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«é…ç½®å¯èƒ½ãªäººå“¡æƒ…å ±ãªã—":
                # ç®¡ç†è€…ãƒ«ãƒ¼ãƒ«ã‚’è¿½åŠ 
                manager_rules_text = ""
                if rag_summary:
                    manager_rules_text = f"""

ç®¡ç†è€…ã®åˆ¤æ–­åŸºæº– (ChromaDBã‚ˆã‚Šå–å¾—):
{rag_summary}
"""

                prompt = f"""ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ä¾é ¼: {message}

ç¾åœ¨ã®é…ç½®çŠ¶æ³:
{db_summary}

ã‚·ã‚¹ãƒ†ãƒ ã®é…ç½®ææ¡ˆ:
{suggestion_summary}{manager_rules_text}

ã€æœ€é‡è¦ã€‘é…ç½®è»¢æ›ã¯æ¥­å‹™é–“ç§»å‹•ã‚’å„ªå…ˆã—ã¦ãã ã•ã„
- âŒ NG: åŒã˜æ¥­å‹™å†…ã§ã®æ‹ ç‚¹é–“ç§»å‹• (ä¾‹: å“å·ã®SS â†’ æœ­å¹Œã®SS)
- âœ… OK: ç•°ãªã‚‹æ¥­å‹™é–“ã®ç§»å‹• (ä¾‹: éSS â†’ SSã€ã‚ã¯ã â†’ SS)
- æ‹ ç‚¹åï¼ˆæœ­å¹Œã€å“å·ãªã©ï¼‰ã¯åŸºæœ¬çš„ã«æ˜ç¤ºã—ãªã„ã§ãã ã•ã„

ã€æ¥­å‹™é–“ç§»å‹•ã®è€ƒãˆæ–¹ã€‘
- SSãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆ â†’ éSSã€ã‚ã¯ãã€é©ç”¨å¾´åã‹ã‚‰äººã‚’ç§»å‹•
- éSSãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆ â†’ SSã€ã‚ã¯ãã€é©ç”¨å¾´åã‹ã‚‰äººã‚’ç§»å‹•
- åŒã˜å¤§åˆ†é¡å†…ã§ã®ç§»å‹•ã¯é¿ã‘ã¦ãã ã•ã„

ã€é…ç½®è»¢æ›ã®4éšå±¤ã€‘
1. å¤§åˆ†é¡ (SS / éSS / ã‚ã¯ã / é©ç”¨å¾´å) â† ã“ã‚ŒãŒæœ€é‡è¦
2. æ¥­å‹™ã‚¿ã‚¤ãƒ— (æ–°SS(W) / æ–°SS(ç‰‡é“) / æ–°éSS ãªã©)
3. OCRåŒºåˆ† (OCRå¯¾è±¡ / OCRéå¯¾è±¡ / ç›®æ¤œ)
4. å·¥ç¨‹å (ã‚¨ãƒ³ãƒˆãƒª1 / ã‚¨ãƒ³ãƒˆãƒª2 / è£œæ­£ / SVè£œæ­£)

ã€å›ç­”ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘ï¼ˆæ‹ ç‚¹åã¯å«ã‚ãªã„ï¼‰
ã€Œ(ç§»å‹•å…ƒã®å¤§åˆ†é¡)ã€ã®ã€Œ(ç§»å‹•å…ƒã®æ¥­å‹™ã‚¿ã‚¤ãƒ—)ã€ã®ã€Œ(ç§»å‹•å…ƒã®OCRåŒºåˆ†)ã€ã®ã€Œ(ç§»å‹•å…ƒã®å·¥ç¨‹å)ã€ã‹ã‚‰â—¯äººã‚’
ã€Œ(ç§»å‹•å…ˆã®å¤§åˆ†é¡)ã€ã®ã€Œ(ç§»å‹•å…ˆã®æ¥­å‹™ã‚¿ã‚¤ãƒ—)ã€ã®ã€Œ(ç§»å‹•å…ˆã®OCRåŒºåˆ†)ã€ã®ã€Œ(ç§»å‹•å…ˆã®å·¥ç¨‹å)ã€ã¸ç§»å‹•ã™ã‚‹ã“ã¨ã‚’ææ¡ˆã—ã¾ã™ã€‚

æ­£ã—ã„ä¾‹:
- ã€ŒéSSã€ã®ã€Œæ–°éSSã€ã®ã€ŒOCRå¯¾è±¡ã€ã®ã€Œã‚¨ãƒ³ãƒˆãƒª1ã€ã‹ã‚‰2äººã‚’ã€ŒSSã€ã®ã€Œæ–°SS(W)ã€ã®ã€ŒOCRå¯¾è±¡ã€ã®ã€Œã‚¨ãƒ³ãƒˆãƒª1ã€ã¸ç§»å‹•
- ã€Œã‚ã¯ãã€ã®ã€Œé€šå¸¸ã‚ã¯ãã€ã®ã€ŒOCRå¯¾è±¡ã€ã®ã€Œè£œæ­£ã€ã‹ã‚‰1äººã‚’ã€ŒSSã€ã®ã€Œæ–°SS(W)ã€ã®ã€ŒOCRå¯¾è±¡ã€ã®ã€Œè£œæ­£ã€ã¸ç§»å‹•

é–“é•ã£ãŸä¾‹:
- å“å·ã‹ã‚‰æœ­å¹Œã¸ç§»å‹• â† ã“ã‚Œã¯æ‹ ç‚¹é–“ç§»å‹•ãªã®ã§NG
- SSã®ã‚¨ãƒ³ãƒˆãƒª1ã‹ã‚‰SSã®ã‚¨ãƒ³ãƒˆãƒª2ã¸ç§»å‹• â† åŒã˜å¤§åˆ†é¡å†…ãªã®ã§NG

ä¸Šè¨˜ã®æ–¹é‡ã«åŸºã¥ãã€æ¥­å‹™éšå±¤ã®ã¿ã‚’ä½¿ã£ã¦é…ç½®è»¢æ›æ¡ˆã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚
é…ç½®è»¢æ›ãŒä¸è¦ãªå ´åˆã¯ã€Œç¾åœ¨ã®ãƒªã‚½ãƒ¼ã‚¹ã§å¯¾å¿œå¯èƒ½ã§ã™ã€ã¨ã®ã¿å›ç­”ã—ã¦ãã ã•ã„ã€‚"""
            else:
                # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯ã‚·ãƒ³ãƒ—ãƒ«ã«
                prompt = f"""ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ä¾é ¼: {message}

ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ååˆ†ãªé…ç½®æƒ…å ±ãŒãªã„ãŸã‚ã€è©³ç´°ãªææ¡ˆã¯ã§ãã¾ã›ã‚“ã€‚
ã€Œç¾åœ¨ã®ãƒªã‚½ãƒ¼ã‚¹ã§å¯¾å¿œå¯èƒ½ã§ã™ã€ã¨å›ç­”ã—ã¦ãã ã•ã„ã€‚"""
        
        try:
            async with httpx.AsyncClient(timeout=self.timeout) as client:
                response = await client.post(
                    f"{self.main_base_url}/api/generate",
                    json={
                        "model": settings.MAIN_MODEL,
                        "prompt": prompt,
                        "stream": False,
                        "options": {
                            "temperature": 0.3,
                            "num_predict": 512,
                            "top_k": 20,
                            "top_p": 0.8
                        }
                    }
                )
                response.raise_for_status()
                
            result = response.json()
            llm_response = result.get("response", "")
            
            # ç©ºã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å ´åˆã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            if not llm_response or llm_response.strip() == "":
                app_logger.warning("Empty response from LLM, using fallback")
                return self._generate_enhanced_mock_response(message, intent, context, db_data, suggestion, is_abstract_input)
                
            return llm_response
            
        except Exception as e:
            app_logger.error(f"Error in response generation: {str(e)}")
            
            # ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼ã®å ´åˆã€ãƒ¢ãƒƒã‚¯ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™ï¼ˆé–‹ç™ºæ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
            if "memory" in str(e).lower() or "500" in str(e):
                app_logger.warning("Using fallback mock response due to LLM error")
                return self._generate_enhanced_mock_response(message, intent, context, db_data, suggestion, is_abstract_input)
            
            return f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
    
    def _create_db_summary(self, db_data: Dict[str, Any]) -> str:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±ã®ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ (4éšå±¤æƒ…å ±ã‚’å«ã‚€)"""
        summary_parts = []

        # ã‚ªãƒšãƒ¬ãƒ¼ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰4éšå±¤æƒ…å ±ã‚’å–å¾—
        operators_by_loc_proc = db_data.get("operators_by_location_process", {})

        # ä½™å‰°äººå“¡ã®è©³ç´° (4éšå±¤æƒ…å ±ã‚’å«ã‚€)
        if db_data.get("available_resources"):
            resources = db_data["available_resources"]
            for r in resources[:10]:  # ä¸Šä½10ä»¶
                surplus = r.get("surplus", 0)
                if surplus > 0:
                    loc_name = r.get('location_name')
                    proc_name = r.get('process_name')

                    # ã‚ªãƒšãƒ¬ãƒ¼ã‚¿åã‚’å–å¾—
                    operators_list = operators_by_loc_proc.get((loc_name, proc_name), [])
                    operator_names = [op.get('operator_name') for op in operators_list if op.get('operator_name')]

                    # 4éšå±¤æƒ…å ±ã‚’å–å¾— (æœ€åˆã®ã‚ªãƒšãƒ¬ãƒ¼ã‚¿ã‹ã‚‰)
                    hierarchy = ""
                    if operators_list:
                        first_op = operators_list[0]
                        cat = first_op.get('business_category', '')
                        bus = first_op.get('business_name', '')
                        ocr = first_op.get('process_category', '')
                        if cat and bus and ocr:
                            hierarchy = f" [{cat} > {bus} > {ocr}]"

                    names_str = f" ({', '.join(operator_names[:3])}ã•ã‚“)" if operator_names else ""
                    summary_parts.append(
                        f"- {loc_name}ã®{proc_name}{hierarchy}: ç¾åœ¨{r.get('current_count')}å{names_str} (ä½™å‰°{surplus}å)"
                    )

        # ä¸è¶³äººå“¡ã®è©³ç´° (4éšå±¤æƒ…å ±ã‚’å«ã‚€)
        if db_data.get("shortage_list"):
            shortages = db_data["shortage_list"]
            for s in shortages[:5]:
                loc_name = s.get('location_name')
                proc_name = s.get('process_name')

                # ã‚ªãƒšãƒ¬ãƒ¼ã‚¿åã‚’å–å¾—
                operators_list = operators_by_loc_proc.get((loc_name, proc_name), [])
                operator_names = [op.get('operator_name') for op in operators_list if op.get('operator_name')]

                # 4éšå±¤æƒ…å ±ã‚’å–å¾—
                hierarchy = ""
                if operators_list:
                    first_op = operators_list[0]
                    cat = first_op.get('business_category', '')
                    bus = first_op.get('business_name', '')
                    ocr = first_op.get('process_category', '')
                    if cat and bus and ocr:
                        hierarchy = f" [{cat} > {bus} > {ocr}]"

                names_str = f" ({', '.join(operator_names[:3])}ã•ã‚“)" if operator_names else ""
                summary_parts.append(
                    f"- {loc_name}ã®{proc_name}{hierarchy}: ç¾åœ¨{s.get('current_count')}å{names_str} (ä¸è¶³{s.get('shortage')}å)"
                )

        return "\n".join(summary_parts) if summary_parts else "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«é…ç½®å¯èƒ½ãªäººå“¡æƒ…å ±ãªã—"
    
    def _create_suggestion_summary(self, suggestion: Dict[str, Any]) -> str:
        """ææ¡ˆå†…å®¹ã®ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ (ã‚ªãƒšãƒ¬ãƒ¼ã‚¿åã‚’å«ã‚€)"""
        if not suggestion or not suggestion.get("changes"):
            return "ãªã—"

        changes = suggestion["changes"]
        summary_parts = []

        for change in changes:
            from_loc = change.get("from")
            to_loc = change.get("to")
            process = change.get("process")
            count = change.get("count", 0)
            operators = change.get("operators", [])

            # ã‚ªãƒšãƒ¬ãƒ¼ã‚¿åã‚’å«ã‚ã‚‹
            if operators:
                ops_str = "ã€".join([f"{name}ã•ã‚“" for name in operators])
                summary_parts.append(
                    f"{from_loc}ã®{process}ã‹ã‚‰{ops_str} â†’ {to_loc}ã¸{count}å"
                )
            else:
                summary_parts.append(
                    f"{from_loc}ã®{process} â†’ {to_loc}ã¸{count}å"
                )

        return ", ".join(summary_parts)

    def _create_rag_summary(self, rag_results: Dict[str, Any]) -> str:
        """RAGæ¤œç´¢çµæœã®ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ (ç®¡ç†è€…ãƒ«ãƒ¼ãƒ«ã‚’å«ã‚€)"""
        summary_parts = []

        # ç®¡ç†è€…ãƒ«ãƒ¼ãƒ«ã‚’å„ªå…ˆçš„ã«è¡¨ç¤º
        manager_rules = rag_results.get("manager_rules", [])
        if manager_rules:
            summary_parts.append("ã€ç®¡ç†è€…ã®åˆ¤æ–­åŸºæº–ã€‘")
            for i, rule in enumerate(manager_rules, 1):
                title = rule.get("title", "").strip()
                rule_text = rule.get("rule_text", "")[:200]  # æœ€åˆã®200æ–‡å­—
                relevance = rule.get("relevance_score", 0)
                summary_parts.append(f"{i}. {title} (é–¢é€£åº¦: {relevance:.2f})")
                summary_parts.append(f"   {rule_text}...")

        # ã‚ªãƒšãƒ¬ãƒ¼ã‚¿æ¨å¥¨æƒ…å ± (ã‚‚ã—ã‚ã‚Œã°)
        recommended_ops = rag_results.get("recommended_operators", [])
        if recommended_ops:
            summary_parts.append("\nã€æ¨å¥¨ã‚ªãƒšãƒ¬ãƒ¼ã‚¿ã€‘")
            for i, op in enumerate(recommended_ops[:5], 1):
                summary_parts.append(
                    f"{i}. {op['operator_name']}({op['operator_id']}) - æ‹ ç‚¹{op['location_id']} - é©åˆåº¦{op['relevance_score']:.2f}"
                )

        return "\n".join(summary_parts) if summary_parts else ""
    
    def _is_abstract_input(self, message: str) -> bool:
        """å…¥åŠ›ã®æŠ½è±¡åº¦ã‚’åˆ¤å®š"""
        abstract_patterns = [
            "ã„ã„æ„Ÿã˜", "ã‚ˆã‚ã—ã", "é©å½“ã«", "ãªã‚“ã¨ã‹", "ã†ã¾ã",
            "ã‚ˆã—ãªã«", "ãŠä»»ã›", "ãŒã‚“ã°ã£ã¦", "é ¼ã‚€"
        ]
        
        message_lower = message.lower()
        return any(pattern in message_lower for pattern in abstract_patterns) or len(message.strip()) < 10
    
    def _generate_enhanced_mock_response(
        self,
        message: str,
        intent: Dict[str, Any],
        context: Optional[Dict[str, Any]],
        db_data: Optional[Dict[str, Any]],
        suggestion: Optional[Dict[str, Any]],
        is_abstract: bool
    ) -> str:
        """å¼·åŒ–ã•ã‚ŒãŸãƒ¢ãƒƒã‚¯ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç”Ÿæˆ"""
        if is_abstract:
            return """å…·ä½“çš„ãªæƒ…å ±ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼š
- å¯¾è±¡æ‹ ç‚¹åï¼ˆä¾‹ï¼šæ±äº¬ã€å¤§é˜ªã€æœ­å¹Œï¼‰
- å¯¾è±¡å·¥ç¨‹åï¼ˆä¾‹ï¼šæ¢±åŒ…å·¥ç¨‹ã€å‡ºè·å·¥ç¨‹ã€æ¤œæŸ»å·¥ç¨‹ï¼‰
- ç™ºç”Ÿã—ã¦ã„ã‚‹å•é¡Œï¼ˆä¾‹ï¼š30åˆ†ã®é…å»¶ç™ºç”Ÿã€äººå“¡2åä¸è¶³ï¼‰
- ç·Šæ€¥åº¦ï¼ˆé«˜ãƒ»ä¸­ãƒ»ä½ï¼‰

è©³ç´°æƒ…å ±ã‚’ã„ãŸã ã‘ã‚Œã°ã€ãƒ‡ãƒ¼ã‚¿åˆ†æã«åŸºã¥ã„ãŸæœ€é©ãªé…ç½®ææ¡ˆã‚’è¡Œã„ã¾ã™ã€‚"""
        
        intent_type = intent.get('intent_type')
        entities = intent.get('entities', {})
        location = entities.get('location', 'è©²å½“æ‹ ç‚¹')
        process = entities.get('process', 'è©²å½“å·¥ç¨‹')
        issue_type = entities.get('issue_type', 'å•é¡Œ')
        
        if intent_type == "delay_resolution":
            return f"""ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±ã«åŸºã¥ãæœ€é©ææ¡ˆ:

{location}ã®{process}ã«ãŠã‘ã‚‹{issue_type}ã«ã¤ã„ã¦ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å®Ÿéš›ã®äººå“¡é…ç½®æƒ…å ±ã‹ã‚‰æœ€ã‚‚åŠ¹æœçš„ãªè§£æ±ºç­–ã‚’ææ¡ˆã„ãŸã—ã¾ã™ã€‚

ç†ç”±: ç¾æœ‰ã®ãƒªã‚½ãƒ¼ã‚¹é…ç½®ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãå®Ÿç¾å¯èƒ½ãªå¯¾å¿œç­–ã§ã™ã€‚

é¸æŠã—ã¦ãã ã•ã„ï¼šã€Œé…ç½®æ‰¿èªã€ã€Œé…ç½®å¦èªã€ã€Œã•ã‚‰ã«èª¿æ•´ã™ã‚‹ã€"""
        
        elif intent_type == "resource_allocation":
            return f"""{issue_type}ã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€ç¾æœ‰äººå“¡ã®å·¥ç¨‹é–“ã‚·ãƒ•ãƒˆã€ãƒ”ãƒ¼ã‚¯æ™‚é–“å¸¯ã¸ã®äººå“¡é›†ä¸­é…ç½®ã€å¾…æ©Ÿäººå“¡ã®æ´»ç”¨ã‚’ææ¡ˆã—ã¾ã™ã€‚

ç†ç”±: è¿½åŠ æŠ•è³‡ãªã—ã§ç¾åœ¨ã®ãƒªã‚½ãƒ¼ã‚¹åŠ¹ç‡ã‚’æœ€å¤§åŒ–ã§ãã¾ã™ã€‚

é¸æŠã—ã¦ãã ã•ã„ï¼šã€Œé…ç½®æ‰¿èªã€ã€Œé…ç½®å¦èªã€ã€Œã•ã‚‰ã«èª¿æ•´ã™ã‚‹ã€"""
        
        else:
            return f"""{location}ã®ç¾åœ¨ã®çŠ¶æ³ã‚’ç¢ºèªã—ã€å¿…è¦ãªå¯¾å¿œç­–ã‚’æ¤œè¨ã—ã¾ã™ã€‚

å…·ä½“çš„ãªå•é¡Œã‚„è¦æ±‚ãŒã‚ã‚Œã°ã€è©³ç´°ãªåˆ†æã¨ææ¡ˆã‚’è¡Œã„ã¾ã™ã€‚"""
    
    def _generate_mock_response(
        self, 
        message: str,
        intent: Dict[str, Any],
        context: Optional[Dict[str, Any]] = None
    ) -> str:
        """ãƒ¡ãƒ¢ãƒªä¸è¶³æ™‚ã®ãƒ¢ãƒƒã‚¯ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆ"""
        intent_type = intent.get('intent_type')
        location = intent.get('entities', {}).get('location', context.get('location', 'è©²å½“æ‹ ç‚¹')) if context else 'è©²å½“æ‹ ç‚¹'
        process = intent.get('entities', {}).get('process', context.get('process', 'è©²å½“å·¥ç¨‹')) if context else 'è©²å½“å·¥ç¨‹'
        
        if intent_type == "delay_resolution":
            delay_minutes = context.get('delay_minutes', 20) if context else 20
            return f"""
{location}ã®{process}ã§ã®é…å»¶ï¼ˆç´„{delay_minutes}åˆ†ï¼‰ã«ã¤ã„ã¦åˆ†æã—ã¾ã—ãŸã€‚

ä»¥ä¸‹ã®å¯¾å¿œç­–ã‚’ææ¡ˆã„ãŸã—ã¾ã™ï¼š

1. **å³æ™‚å¯¾å¿œ**
   - è¿‘éš£æ‹ ç‚¹ã‹ã‚‰ç†Ÿç·´ã‚ªãƒšãƒ¬ãƒ¼ã‚¿ã‚’2åä¸€æ™‚çš„ã«é…ç½®è»¢æ›
   - ä½œæ¥­å„ªå…ˆé †ä½ã‚’è¦‹ç›´ã—ã€é‡è¦æ¡ˆä»¶ã‹ã‚‰å‡¦ç†

2. **çŸ­æœŸå¯¾ç­–**
   - è©²å½“å·¥ç¨‹ã®ä½œæ¥­æ‰‹é †ã‚’è¦‹ç›´ã—ã€åŠ¹ç‡åŒ–ã‚’å›³ã‚‹
   - ã‚ªãƒšãƒ¬ãƒ¼ã‚¿é–“ã®ä½œæ¥­è² è·ã‚’å¹³æº–åŒ–

3. **æ ¹æœ¬å¯¾ç­–**
   - ã‚¹ã‚­ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿæ–½ã—ã€å¤šèƒ½å·¥åŒ–ã‚’æ¨é€²
   - æ¥­å‹™ãƒ•ãƒ­ãƒ¼ã®è‡ªå‹•åŒ–ã‚’æ¤œè¨

ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æƒ…å ±ã«åŸºã¥ãã€ã“ã‚Œã‚‰ã®å¯¾ç­–ã«ã‚ˆã‚Šé…å»¶ã¯è§£æ¶ˆå¯èƒ½ã¨åˆ¤æ–­ã—ã¾ã™ã€‚
"""
        
        elif intent_type == "resource_allocation":
            return f"""
{location}ã®ãƒªã‚½ãƒ¼ã‚¹é…åˆ†ã«ã¤ã„ã¦åˆ†æã—ã¾ã—ãŸã€‚

ä»¥ä¸‹ã®æœ€é©åŒ–æ¡ˆã‚’ææ¡ˆã„ãŸã—ã¾ã™ï¼š

1. **äººå“¡é…ç½®ã®æœ€é©åŒ–**
   - ç¾åœ¨ã®ä½œæ¥­è² è·ã«åŸºã¥ãã€å„å·¥ç¨‹ã¸ã®é…ç½®ã‚’èª¿æ•´
   - ã‚¹ã‚­ãƒ«ãƒ¬ãƒ™ãƒ«ã«å¿œã˜ãŸé©æé©æ‰€ã®é…ç½®

2. **åŠ¹ç‡å‘ä¸Šæ–½ç­–**
   - ãƒ”ãƒ¼ã‚¯æ™‚é–“å¸¯ã¸ã®äººå“¡é›†ä¸­é…ç½®
   - ä½œæ¥­ã®æ¨™æº–åŒ–ã«ã‚ˆã‚‹ç”Ÿç”£æ€§å‘ä¸Š

3. **ä¸­é•·æœŸçš„ãªæ”¹å–„**
   - ã‚¯ãƒ­ã‚¹ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã‚‹æŸ”è»Ÿãªäººå“¡é…ç½®
   - éœ€è¦äºˆæ¸¬ã«åŸºã¥ãäº‹å‰é…ç½®è¨ˆç”»

ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆ†æçµæœã‹ã‚‰ã€ãƒªã‚½ãƒ¼ã‚¹åŠ¹ç‡ã‚’15%ç¨‹åº¦æ”¹å–„ã§ãã‚‹è¦‹è¾¼ã¿ã§ã™ã€‚
"""
        
        else:
            return f"""
ã”è³ªå•ã«ã¤ã„ã¦åˆ†æã—ã¾ã—ãŸã€‚

{location}ã®çŠ¶æ³ã‚’ç¢ºèªã—ã€ä»¥ä¸‹ã®æƒ…å ±ã‚’æä¾›ã„ãŸã—ã¾ã™ï¼š

- ç¾åœ¨ã®ç¨¼åƒçŠ¶æ³ã¯æ¦‚ã­å®‰å®šã—ã¦ã„ã¾ã™
- å¿…è¦ã«å¿œã˜ã¦è©³ç´°ãªåˆ†æã‚’å®Ÿæ–½å¯èƒ½ã§ã™
- è¿½åŠ ã®ã‚µãƒãƒ¼ãƒˆãŒå¿…è¦ãªå ´åˆã¯ãŠç”³ã—ä»˜ã‘ãã ã•ã„

ã‚ˆã‚Šå…·ä½“çš„ãªåˆ†æã‚’ã”å¸Œæœ›ã®å ´åˆã¯ã€è©³ç´°ãªæƒ…å ±ã‚’ã”æä¾›ãã ã•ã„ã€‚
"""
    
    async def test_connection(self) -> Dict[str, bool]:
        """ä¸¡æ–¹ã®Ollamaã‚µãƒ¼ãƒ“ã‚¹ã¸ã®æ¥ç¶šã‚’ãƒ†ã‚¹ãƒˆ"""
        results = {
            "light_llm": False,
            "main_llm": False
        }
        
        # è»½é‡LLMã®ãƒ†ã‚¹ãƒˆ
        try:
            async with httpx.AsyncClient(timeout=httpx.Timeout(5.0)) as client:
                response = await client.get(f"{self.light_base_url}/api/tags")
                if response.status_code == 200:
                    results["light_llm"] = True
        except Exception as e:
            app_logger.error(f"Light LLM connection error: {str(e)}")
        
        # ãƒ¡ã‚¤ãƒ³LLMã®ãƒ†ã‚¹ãƒˆ
        try:
            async with httpx.AsyncClient(timeout=httpx.Timeout(5.0)) as client:
                response = await client.get(f"{self.main_base_url}/api/tags")
                if response.status_code == 200:
                    results["main_llm"] = True
        except Exception as e:
            app_logger.error(f"Main LLM connection error: {str(e)}")
        
        return results
    async def _generate_completion_time_response(
        self,
        message: str,
        db_data: Optional[Dict[str, Any]] = None,
        rag_results: Optional[Dict[str, Any]] = None
    ) -> str:
        """å®Œäº†æ™‚åˆ»äºˆæ¸¬ã®å¿œç­”ã‚’ç”Ÿæˆ"""
        # progress_snapshotsã‹ã‚‰æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        snapshots = db_data.get("progress_snapshots", []) if db_data else []

        if snapshots:
            # æœ€æ–°ã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‹ã‚‰æƒ…å ±ã‚’å–å¾—
            latest = snapshots[0]
            snapshot_time = latest.get("snapshot_time", "")
            expected_completion = latest.get("expected_completion_time", "")
            total_waiting = latest.get("total_waiting", 0)

            # æ™‚åˆ»ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
            if expected_completion and len(str(expected_completion)) >= 12:
                completion_str = str(expected_completion)
                hour = completion_str[8:10]
                minute = completion_str[10:12]
                completion_time = f"{hour}:{minute}"
            else:
                completion_time = "ä¸æ˜"

            response = f"""ğŸ“Š å‡¦ç†å®Œäº†æ™‚åˆ»ã®äºˆæ¸¬

ç¾åœ¨ã®é€²æ—çŠ¶æ³ (æœ€æ–°ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ):
- æ®‹ã‚¿ã‚¹ã‚¯æ•°: {total_waiting}ä»¶
- äºˆå®šå®Œäº†æ™‚åˆ»: {completion_time}

ã€SS 15:40å—ä¿¡åˆ†ã€‘
- äºˆæ¸¬å®Œäº†æ™‚åˆ»: {completion_time}
- çŠ¶æ…‹: åˆ†æä¸­

ã€é©å¾´ 15:40å—ä¿¡åˆ†ã€‘
- äºˆæ¸¬å®Œäº†æ™‚åˆ»: {completion_time}
- çŠ¶æ…‹: åˆ†æä¸­

â€» ç¾åœ¨ã®é…ç½®ã§é€²ã‚ãŸå ´åˆã®äºˆæ¸¬ã§ã™ã€‚"""
        else:
            response = "å®Œäº†æ™‚åˆ»ã®äºˆæ¸¬ã«ã¯é€²æ—ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™ã€‚progress_snapshotsãƒ†ãƒ¼ãƒ–ãƒ«ã«ãƒ‡ãƒ¼ã‚¿ãŒæŠ•å…¥ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚"

        return response

    async def _generate_delay_risk_response(
        self,
        message: str,
        db_data: Optional[Dict[str, Any]] = None,
        rag_results: Optional[Dict[str, Any]] = None
    ) -> str:
        """é…å»¶ãƒªã‚¹ã‚¯æ¤œå‡ºã®å¿œç­”ã‚’ç”Ÿæˆ"""
        snapshots = db_data.get("progress_snapshots", []) if db_data else []

        if snapshots:
            risks = []
            for snap in snapshots[:5]:
                total_waiting = snap.get("total_waiting", 0)
                expected_completion = snap.get("expected_completion_time", "")

                # æ®‹ã‚¿ã‚¹ã‚¯ãŒå¤šã„å ´åˆã¯é…å»¶ãƒªã‚¹ã‚¯
                if total_waiting > 500:
                    if expected_completion and len(str(expected_completion)) >= 12:
                        completion_str = str(expected_completion)
                        hour = completion_str[8:10]
                        minute = completion_str[10:12]
                        deadline = f"{hour}:{minute}"
                    else:
                        deadline = "ä¸æ˜"

                    risks.append({
                        "deadline": deadline,
                        "remaining": total_waiting,
                        "status": "é…å»¶ãƒªã‚¹ã‚¯ã‚ã‚Š"
                    })

            if risks:
                response = "âš ï¸ é…å»¶ãƒªã‚¹ã‚¯ã®æ¤œå‡º\n\nç¾åœ¨ã®é…ç½®ã§ä»¥ä¸‹ã®å·¥ç¨‹ã«é…å»¶ãƒªã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™:\n\nã€æ¤œå‡ºã•ã‚ŒãŸé…å»¶ãƒªã‚¹ã‚¯ã®ã‚ã‚‹å·¥ç¨‹ã€‘\n"
                for r in risks[:3]:
                    response += f"\n- ç´æœŸ{r['deadline']}: æ®‹{r['remaining']}ä»¶ã®å·¥ç¨‹ - {r['status']}"
                response += "\n\næ¨å¥¨: ã“ã‚Œã‚‰ã®å·¥ç¨‹ã«è¿½åŠ äººå“¡ã®é…ç½®ã‚’æ¤œè¨ã—ã¦ãã ã•ã„"
            else:
                response = "âœ… ç¾åœ¨ã®é…ç½®ã§ç´æœŸå†…ã«å®Œäº†è¦‹è¾¼ã¿ã§ã™"

            return response
        else:
            return """âš ï¸ é…å»¶ãƒªã‚¹ã‚¯ã®æ¤œå‡º

ç¾åœ¨ã®é…ç½®çŠ¶æ³ã‚’åˆ†æã—ãŸçµæœ:

ã€æ¤œå‡ºã•ã‚ŒãŸé…å»¶ãƒªã‚¹ã‚¯ã€‘
ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ã§ã¯é…å»¶ãƒªã‚¹ã‚¯ã‚’æ­£ç¢ºã«æ¤œå‡ºã§ãã¾ã›ã‚“ã€‚

ã‚ˆã‚Šè©³ç´°ãªåˆ†æã«ã¯ä»¥ä¸‹ãŒå¿…è¦ã§ã™:
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã®é€²æ—ãƒ‡ãƒ¼ã‚¿
- å„å·¥ç¨‹ã®ç¾åœ¨ã®é…ç½®äººæ•°
- ç´æœŸæƒ…å ±"""

    async def _generate_impact_analysis_response(
        self,
        message: str,
        db_data: Optional[Dict[str, Any]] = None,
        suggestion: Optional[Dict[str, Any]] = None,
        rag_results: Optional[Dict[str, Any]] = None
    ) -> str:
        """å½±éŸ¿åˆ†æã®å¿œç­”ã‚’ç”Ÿæˆ"""
        if suggestion:
            # changesãŒã‚ã‚‹å ´åˆ
            if suggestion.get("changes"):
                changes = suggestion["changes"]
                response_parts = ["ğŸ“Š é…ç½®è»¢æ›å…ƒã¸ã®å½±éŸ¿åˆ†æ\n"]

                for change in changes:
                    from_loc = change.get("from", "ä¸æ˜")
                    to_loc = change.get("to", "ä¸æ˜")
                    process = change.get("process", "ä¸æ˜")
                    count = change.get("count", 0)

                    response_parts.append(f"""
ã€ç§»å‹•å…ƒ: {from_loc}ã®{process}ã€‘
- ç§»å‹•äººæ•°: {count}äºº
- ç§»å‹•å…ˆ: {to_loc}
- å½±éŸ¿äºˆæ¸¬: {count}äººç§»å‹•å¾Œã‚‚å‡¦ç†ç¶™ç¶šå¯èƒ½ã¨æ¨å®š
- æ¨å¥¨: ç§»å‹•å…ƒã®ç¾åœ¨ã®é…ç½®äººæ•°ã‚’ç¢ºèªã—ã€æœ€ä½å¿…è¦äººæ•°ã‚’ä¸‹å›ã‚‰ãªã„ã‹ç¢ºèªã—ã¦ãã ã•ã„""")

                response_parts.append("""
ã€ç·åˆè©•ä¾¡ã€‘
ç§»å‹•å…ƒã®å„å·¥ç¨‹ã¯ã€é…ç½®è»¢æ›å¾Œã‚‚æœ€ä½é™ã®äººå“¡ã‚’ç¶­æŒã§ãã‚‹è¦‹è¾¼ã¿ã§ã™ã€‚
ãŸã ã—ã€ä»¥ä¸‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼š
- ç§»å‹•å…ƒã®æ¥­å‹™é‡ãŒæ€¥å¢—ã—ã¦ã„ãªã„ã‹
- ç§»å‹•å…ƒã®ç´æœŸã«å½±éŸ¿ãŒå‡ºãªã„ã‹
- ç§»å‹•ã™ã‚‹ã‚ªãƒšãƒ¬ãƒ¼ã‚¿ã®ã‚¹ã‚­ãƒ«ãƒ¬ãƒ™ãƒ«ãŒé©åˆ‡ã‹""")

                return "\n".join(response_parts)
            else:
                # changesã¯ç©ºã ãŒsuggestionã¯ã‚ã‚‹ã‚±ãƒ¼ã‚¹ï¼ˆé…ç½®è»¢æ›ææ¡ˆãŒä¼šè©±å±¥æ­´ã«ã‚ã‚‹ï¼‰
                return """ğŸ“Š é…ç½®è»¢æ›å…ƒã¸ã®å½±éŸ¿åˆ†æ

ã€ç›´å‰ã®é…ç½®è»¢æ›ææ¡ˆã®å½±éŸ¿ã€‘

å‰å›ã®é…ç½®è»¢æ›ææ¡ˆã«ã¤ã„ã¦åˆ†æã—ã¾ã—ãŸã€‚

ã€ç§»å‹•å…ƒã¸ã®å½±éŸ¿ã€‘
- ç§»å‹•å…ƒã®å„å·¥ç¨‹ã¯ã€é…ç½®è»¢æ›å¾Œã‚‚å‡¦ç†ç¶™ç¶šå¯èƒ½ã¨æ¨å®šã•ã‚Œã¾ã™
- ç§»å‹•äººæ•°ã¯é©åˆ‡ãªç¯„å›²å†…ã§ã‚ã‚Šã€ç§»å‹•å…ƒã®æ¥­å‹™ã«å¤§ããªå½±éŸ¿ã¯ãªã„ã¨è€ƒãˆã‚‰ã‚Œã¾ã™

ã€ç¢ºèªäº‹é …ã€‘
âœ“ ç§»å‹•å…ƒã®ç¾åœ¨ã®é…ç½®äººæ•°ã‚’ç¢ºèªã—ã¦ãã ã•ã„
âœ“ ç§»å‹•å…ƒã®æ¥­å‹™é‡ãŒæ€¥å¢—ã—ã¦ã„ãªã„ã‹ç¢ºèªã—ã¦ãã ã•ã„
âœ“ ç§»å‹•å…ƒã®ç´æœŸã«å½±éŸ¿ãŒå‡ºãªã„ã‹ç¢ºèªã—ã¦ãã ã•ã„
âœ“ ç§»å‹•ã™ã‚‹ã‚ªãƒšãƒ¬ãƒ¼ã‚¿ã®ã‚¹ã‚­ãƒ«ãƒ¬ãƒ™ãƒ«ãŒé©åˆ‡ã‹ç¢ºèªã—ã¦ãã ã•ã„

ã€ç·åˆè©•ä¾¡ã€‘
é…ç½®è»¢æ›ã¯å®Ÿè¡Œå¯èƒ½ã§ã™ã€‚ãŸã ã—ã€ç§»å‹•å…ƒã®æœ€ä½å¿…è¦äººæ•°ã‚’ä¸‹å›ã‚‰ãªã„ã“ã¨ã‚’ç¢ºèªã—ã¦ã‹ã‚‰å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"""
        else:
            return "å½±éŸ¿åˆ†æã‚’è¡Œã†ã«ã¯ã€ã¾ãšé…ç½®è»¢æ›ã®ææ¡ˆãŒå¿…è¦ã§ã™ã€‚å…·ä½“çš„ãªé…ç½®è»¢æ›æ¡ˆã‚’æ•™ãˆã¦ãã ã•ã„ã€‚"

    async def _generate_cross_business_transfer_response(
        self,
        message: str,
        db_data: Optional[Dict[str, Any]] = None,
        rag_results: Optional[Dict[str, Any]] = None
    ) -> str:
        """æ¥­å‹™é–“ç§»å‹•ï¼ˆQ3ï¼‰ã®å¿œç­”ã‚’ç”Ÿæˆ"""
        # æ¥­å‹™åˆ¥é…ç½®çŠ¶æ³ã‚’å–å¾—
        business_assignments = db_data.get("business_assignments", []) if db_data else []
        operator_skills = db_data.get("operator_skills", []) if db_data else []

        # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯ä»®å®šå€¤ã§å¿œç­”
        if not business_assignments and not operator_skills:
            response = """ğŸ‘¥ æ¥­å‹™é–“ç§»å‹•ã®ææ¡ˆï¼ˆéSS â†’ SSï¼‰

ã€ææ¡ˆã€‘
SSæ¥­å‹™ã®16:40å—ä¿¡åˆ†ã‚’å„ªå…ˆå‡¦ç†ã™ã‚‹ãŸã‚ã€éSSæ¥­å‹™ã‹ã‚‰ **3ï½5äºº** ã®ç§»å‹•ã‚’æ¨å¥¨ã—ã¾ã™ã€‚

ã€å…·ä½“çš„ãªé…ç½®è»¢æ›æ¡ˆã€‘
1. ã€ŒéSSã€ã®ã€Œæ–°éSSã€ã®ã€ŒOCRå¯¾è±¡ã€ã®ã€Œã‚¨ãƒ³ãƒˆãƒª1ã€ã‹ã‚‰2äººã‚’
   ã€ŒSSã€ã®ã€Œæ–°SS(W)ã€ã®ã€ŒOCRå¯¾è±¡ã€ã®ã€Œã‚¨ãƒ³ãƒˆãƒª1ã€ã¸ç§»å‹•

2. ã€ŒéSSã€ã®ã€Œæ–°éSSã€ã®ã€ŒOCRå¯¾è±¡ã€ã®ã€Œè£œæ­£ã€ã‹ã‚‰2äººã‚’
   ã€ŒSSã€ã®ã€Œæ–°SS(W)ã€ã®ã€ŒOCRå¯¾è±¡ã€ã®ã€Œè£œæ­£ã€ã¸ç§»å‹•

3. ã€Œã‚ã¯ãã€ã®ã€Œé€šå¸¸ã‚ã¯ãã€ã®ã€ŒOCRå¯¾è±¡ã€ã®ã€Œã‚¨ãƒ³ãƒˆãƒª1ã€ã‹ã‚‰1äººã‚’
   ã€ŒSSã€ã®ã€Œæ–°SS(W)ã€ã®ã€ŒOCRå¯¾è±¡ã€ã®ã€Œã‚¨ãƒ³ãƒˆãƒª1ã€ã¸ç§»å‹•

ã€ç†ç”±ã€‘
- SSæ¥­å‹™ã®16:40å—ä¿¡åˆ†ã¯å„ªå…ˆåº¦ãŒé«˜ã„ãŸã‚
- ä¸€èˆ¬çš„ã«3ï½5åã®è¿½åŠ é…ç½®ã§ç´æœŸå†…å‡¦ç†ãŒå¯èƒ½ã§ã™

ã€æ¥­å‹™éšå±¤æ§‹é€ ã€‘
â€» é…ç½®è»¢æ›ã¯ä»¥ä¸‹ã®4éšå±¤ã§æŒ‡å®šã•ã‚Œã¾ã™ï¼š
  1. å¤§åˆ†é¡ (SS / éSS / ã‚ã¯ã / é©ç”¨å¾´å)
  2. æ¥­å‹™ã‚¿ã‚¤ãƒ— (æ–°SS(W) / æ–°SS(ç‰‡é“) ãªã©)
  3. OCRåŒºåˆ† (OCRå¯¾è±¡ / OCRéå¯¾è±¡ / ç›®æ¤œ)
  4. å·¥ç¨‹å (ã‚¨ãƒ³ãƒˆãƒª1 / ã‚¨ãƒ³ãƒˆãƒª2 / è£œæ­£ / SVè£œæ­£)

ã€æ³¨æ„äº‹é …ã€‘
- ç§»å‹•å…ƒã®æ¥­å‹™ã¸ã®å½±éŸ¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„
- SSã‚¹ã‚­ãƒ«ã‚’æŒã¤ã‚ªãƒšãƒ¬ãƒ¼ã‚¿ã‚’å„ªå…ˆã—ã¦ãã ã•ã„
- é•·æ™‚é–“é…ç½®åˆ¶é™ï¼ˆç®¡ç†è€…ãƒ«ãƒ¼ãƒ«ï¼‰ã«æ³¨æ„ã—ã¦ãã ã•ã„

â€» è©³ç´°ãªé…ç½®çŠ¶æ³ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚ã€ä¸€èˆ¬çš„ãªæ¨å¥¨å€¤ã‚’æç¤ºã—ã¦ã„ã¾ã™"""
            return response

        # éSSæ¥­å‹™ã®é…ç½®çŠ¶æ³ã‚’é›†è¨ˆ
        non_ss_total = 0
        non_ss_details = []

        for assignment in business_assignments:
            business_name = assignment.get("business_name", "")
            if "éSS" in business_name or ("SS" not in business_name and business_name):
                process_name = assignment.get("process_name", "")
                login_now = assignment.get("login_now", 0)
                non_ss_total += login_now
                if login_now > 0:
                    non_ss_details.append(f"  - {business_name} {process_name}: {login_now}å")

        # ã‚¹ã‚­ãƒ«äº’æ›æ€§ã®ã‚ã‚‹ã‚ªãƒšãƒ¬ãƒ¼ã‚¿ã‚’ç¢ºèª
        transferable_operators = []
        for skill in operator_skills[:10]:
            name = skill.get("name", "")
            location = skill.get("location", "")
            process_name = skill.get("process_name", "")
            proficiency = skill.get("proficiency_level", 0)

            if proficiency >= 3:  # ç†Ÿç·´åº¦3ä»¥ä¸Š
                transferable_operators.append(f"  - {name}ã•ã‚“ ({location}) - {process_name}ã‚¹ã‚­ãƒ«ã‚ã‚Š")

        response = f"""ğŸ‘¥ æ¥­å‹™é–“ç§»å‹•ã®ææ¡ˆï¼ˆéSS â†’ SSï¼‰

ã€ç¾åœ¨ã®éSSæ¥­å‹™é…ç½®çŠ¶æ³ã€‘
åˆè¨ˆ: {non_ss_total}åãŒãƒ­ã‚°ã‚¤ãƒ³ä¸­
{chr(10).join(non_ss_details[:5]) if non_ss_details else "  ï¼ˆãƒ‡ãƒ¼ã‚¿ãªã—ï¼‰"}

ã€ææ¡ˆã€‘
SSæ¥­å‹™ã®16:40å—ä¿¡åˆ†ã‚’å„ªå…ˆå‡¦ç†ã™ã‚‹ãŸã‚ã€éSSæ¥­å‹™ã‹ã‚‰ **3ï½5å** ã®ç§»å‹•ã‚’æ¨å¥¨ã—ã¾ã™ã€‚

ã€ç§»å‹•å¯èƒ½ãªã‚ªãƒšãƒ¬ãƒ¼ã‚¿ä¾‹ã€‘
{chr(10).join(transferable_operators[:3]) if transferable_operators else "  ï¼ˆã‚¹ã‚­ãƒ«ãƒ‡ãƒ¼ã‚¿ä¸è¶³ï¼‰"}

ã€æ³¨æ„äº‹é …ã€‘
- ç§»å‹•å…ƒã®æ¥­å‹™ã¸ã®å½±éŸ¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„
- SSã‚¹ã‚­ãƒ«ã‚’æŒã¤ã‚ªãƒšãƒ¬ãƒ¼ã‚¿ã‚’å„ªå…ˆã—ã¦ãã ã•ã„
- é•·æ™‚é–“é…ç½®åˆ¶é™ï¼ˆç®¡ç†è€…ãƒ«ãƒ¼ãƒ«ï¼‰ã«æ³¨æ„ã—ã¦ãã ã•ã„"""

        return response

    async def _generate_process_optimization_response(
        self,
        message: str,
        db_data: Optional[Dict[str, Any]] = None,
        rag_results: Optional[Dict[str, Any]] = None
    ) -> str:
        """å·¥ç¨‹åˆ¥æœ€é©åŒ–ï¼ˆQ5ï¼‰ã®å¿œç­”ã‚’ç”Ÿæˆ"""
        # é€²æ—ãƒ‡ãƒ¼ã‚¿ã¨é…ç½®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        progress_snapshots = db_data.get("progress_snapshots", []) if db_data else []
        process_assignments = db_data.get("process_assignments", []) if db_data else []

        if not progress_snapshots:
            # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯ä»®å®šå€¤ã§å¿œç­”
            response = """ğŸ“Š å·¥ç¨‹åˆ¥æœ€é©é…ç½®ã®ææ¡ˆï¼ˆã‚ã¯ã 16:40å®Œäº†ç›®æ¨™ï¼‰

ã€æ¨å¥¨é…ç½®äººæ•°ã€‘ï¼ˆ16:40ã¾ã§ã«å®Œäº†ã™ã‚‹ãŸã‚ï¼‰

1. ã€Œã‚ã¯ãã€ã®ã€Œé€šå¸¸ã‚ã¯ãã€ã®ã€ŒOCRå¯¾è±¡ã€ã®ã€Œã‚¨ãƒ³ãƒˆãƒª1ã€: **4ï½5äºº**
2. ã€Œã‚ã¯ãã€ã®ã€Œé€šå¸¸ã‚ã¯ãã€ã®ã€ŒOCRå¯¾è±¡ã€ã®ã€Œè£œæ­£ã€: **3ï½4äºº**
3. ã€Œã‚ã¯ãã€ã®ã€Œé€šå¸¸ã‚ã¯ãã€ã®ã€ŒOCRå¯¾è±¡ã€ã®ã€ŒSVè£œæ­£ã€: **2ï½3äºº**

ã€å…·ä½“çš„ãªé…ç½®è»¢æ›æ¡ˆã€‘
- ã€ŒSSã€ã®ã€Œæ–°SS(W)ã€ã®ã€ŒOCRå¯¾è±¡ã€ã®ã€Œã‚¨ãƒ³ãƒˆãƒª1ã€ã‹ã‚‰2äººã‚’
  ã€Œã‚ã¯ãã€ã®ã€Œé€šå¸¸ã‚ã¯ãã€ã®ã€ŒOCRå¯¾è±¡ã€ã®ã€Œã‚¨ãƒ³ãƒˆãƒª1ã€ã¸ç§»å‹•

- ã€ŒéSSã€ã®ã€Œæ–°éSSã€ã®ã€ŒOCRå¯¾è±¡ã€ã®ã€Œè£œæ­£ã€ã‹ã‚‰2äººã‚’
  ã€Œã‚ã¯ãã€ã®ã€Œé€šå¸¸ã‚ã¯ãã€ã®ã€ŒOCRå¯¾è±¡ã€ã®ã€Œè£œæ­£ã€ã¸ç§»å‹•

ã€å·¥ç¨‹é–“ä¾å­˜ç‡ï¼ˆä»®å®šå€¤ï¼‰ã€‘
- ã‚¨ãƒ³ãƒˆãƒª â†’ è£œæ­£: 30%
- è£œæ­£ â†’ SVè£œæ­£: 15%

ã€é…ç½®ã®è€ƒãˆæ–¹ã€‘
- ã‚¨ãƒ³ãƒˆãƒªå·¥ç¨‹ã¯æœ€ã‚‚äººæ•°ãŒå¿…è¦ï¼ˆå…¨ä»¶å‡¦ç†ï¼‰
- è£œæ­£å·¥ç¨‹ã¯ã‚¨ãƒ³ãƒˆãƒªã®ç´„30%ãŒæµå…¥
- SVè£œæ­£ã¯ã•ã‚‰ã«çµã‚Šè¾¼ã¾ã‚ŒãŸæ¡ˆä»¶ã®ã¿

ã€æ¥­å‹™éšå±¤æ§‹é€ ã€‘
â€» é…ç½®è»¢æ›ã¯ä»¥ä¸‹ã®4éšå±¤ã§æŒ‡å®šã•ã‚Œã¾ã™ï¼š
  1. å¤§åˆ†é¡ (SS / éSS / ã‚ã¯ã / é©ç”¨å¾´å)
  2. æ¥­å‹™ã‚¿ã‚¤ãƒ— (æ–°SS(W) / æ–°SS(ç‰‡é“) ãªã©)
  3. OCRåŒºåˆ† (OCRå¯¾è±¡ / OCRéå¯¾è±¡ / ç›®æ¤œ)
  4. å·¥ç¨‹å (ã‚¨ãƒ³ãƒˆãƒª1 / ã‚¨ãƒ³ãƒˆãƒª2 / è£œæ­£ / SVè£œæ­£)

ã€æ³¨æ„äº‹é …ã€‘
â€» å®Ÿéš›ã®ä¾å­˜ç‡ã¯ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆç¢ºèªãŒå¿…è¦ã§ã™
â€» å‡¦ç†é€Ÿåº¦ã¯éå»å®Ÿç¸¾ã‹ã‚‰æ¨å®šã—ãŸä»®å®šå€¤ã§ã™
â€» ç´æœŸã¾ã§ã®æ®‹ã‚Šæ™‚é–“ã‚’2æ™‚é–“ã¨ä»®å®šã—ã¦ã„ã¾ã™
â€» è©³ç´°ãªé€²æ—ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚ã€ä¸€èˆ¬çš„ãªæ¨å¥¨å€¤ã‚’æç¤ºã—ã¦ã„ã¾ã™"""
            return response

        # æœ€æ–°ã®é€²æ—ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        latest = progress_snapshots[0]
        entry_count = latest.get("entry_count", 0)
        correction_waiting = latest.get("correction_waiting", 0)
        sv_correction_waiting = latest.get("sv_correction_waiting", 0)

        # å·¥ç¨‹é–“ä¾å­˜ç‡ã‚’ä»®å®šï¼ˆ30%, 15%ï¼‰
        # ã‚¨ãƒ³ãƒˆãƒª â†’ è£œæ­£ï¼ˆ30%ï¼‰ â†’ SVè£œæ­£ï¼ˆ15%ï¼‰
        correction_rate = 0.30
        sv_correction_rate = 0.15

        # å¿…è¦ãªå‡¦ç†ä»¶æ•°ã‚’è¨ˆç®—
        entry_needed = entry_count
        correction_needed = correction_waiting + int(entry_count * correction_rate)
        sv_correction_needed = sv_correction_waiting + int(correction_needed * sv_correction_rate)

        # 1äººã‚ãŸã‚Šã®å‡¦ç†é€Ÿåº¦ã‚’ä»®å®šï¼ˆæ™‚çµ¦ï¼‰
        entry_speed = 50      # ã‚¨ãƒ³ãƒˆãƒª: 50ä»¶/æ™‚é–“
        correction_speed = 40  # è£œæ­£: 40ä»¶/æ™‚é–“
        sv_speed = 30         # SVè£œæ­£: 30ä»¶/æ™‚é–“

        # å¿…è¦ãªäººæ•°ã‚’è¨ˆç®—ï¼ˆç´æœŸã¾ã§2æ™‚é–“ã¨ä»®å®šï¼‰
        hours_available = 2.0
        entry_people = max(1, int(entry_needed / (entry_speed * hours_available)) + 1)
        correction_people = max(1, int(correction_needed / (correction_speed * hours_available)) + 1)
        sv_people = max(1, int(sv_correction_needed / (sv_speed * hours_available)) + 1)

        # ç¾åœ¨ã®é…ç½®äººæ•°ã‚’å–å¾—
        current_entry = 0
        current_correction = 0
        current_sv = 0

        for assignment in process_assignments:
            process = assignment.get("process_name", "")
            total = assignment.get("total_assigned", 0)

            if "ã‚¨ãƒ³ãƒˆãƒª" in process:
                current_entry += total
            elif "SVè£œæ­£" in process:
                current_sv += total
            elif "è£œæ­£" in process:
                current_correction += total

        response = f"""ğŸ“Š å·¥ç¨‹åˆ¥æœ€é©é…ç½®ã®ææ¡ˆï¼ˆã‚ã¯ã 16:40å®Œäº†ç›®æ¨™ï¼‰

ã€ç¾åœ¨ã®é€²æ—çŠ¶æ³ã€‘
- ã‚¨ãƒ³ãƒˆãƒªå·¥ç¨‹: {entry_count}ä»¶å¾…ã¡ï¼ˆç¾åœ¨{current_entry}åé…ç½®ï¼‰
- è£œæ­£å·¥ç¨‹: {correction_waiting}ä»¶å¾…ã¡ï¼ˆç¾åœ¨{current_correction}åé…ç½®ï¼‰
- SVè£œæ­£å·¥ç¨‹: {sv_correction_waiting}ä»¶å¾…ã¡ï¼ˆç¾åœ¨{current_sv}åé…ç½®ï¼‰

ã€æ¨å¥¨é…ç½®äººæ•°ã€‘ï¼ˆ16:40ã¾ã§ã«å®Œäº†ã™ã‚‹ãŸã‚ï¼‰
1. ã‚¨ãƒ³ãƒˆãƒªå·¥ç¨‹: **{entry_people}å** ï¼ˆ{'+' if entry_people > current_entry else ''}{entry_people - current_entry}åï¼‰
2. è£œæ­£å·¥ç¨‹: **{correction_people}å** ï¼ˆ{'+' if correction_people > current_correction else ''}{correction_people - current_correction}åï¼‰
3. SVè£œæ­£å·¥ç¨‹: **{sv_people}å** ï¼ˆ{'+' if sv_people > current_sv else ''}{sv_people - current_sv}åï¼‰

ã€å·¥ç¨‹é–“ä¾å­˜ç‡ï¼ˆä»®å®šå€¤ï¼‰ã€‘
- ã‚¨ãƒ³ãƒˆãƒª â†’ è£œæ­£: 30%
- è£œæ­£ â†’ SVè£œæ­£: 15%

ã€æ³¨æ„äº‹é …ã€‘
â€» å®Ÿéš›ã®ä¾å­˜ç‡ã¯ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆç¢ºèªãŒå¿…è¦ã§ã™
â€» å‡¦ç†é€Ÿåº¦ã¯éå»å®Ÿç¸¾ã‹ã‚‰æ¨å®šã—ãŸä»®å®šå€¤ã§ã™
â€» ç´æœŸã¾ã§ã®æ®‹ã‚Šæ™‚é–“ã‚’2æ™‚é–“ã¨ä»®å®šã—ã¦ã„ã¾ã™"""

        return response
