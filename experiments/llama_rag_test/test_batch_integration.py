#!/usr/bin/env python3
"""
ãƒãƒƒãƒ2ï¼ˆæ•°å€¤åˆ†æï¼‰ã¨ãƒãƒƒãƒ3ï¼ˆãƒã‚¦ãƒã‚¦åˆ†æï¼‰ã®çµ±åˆãƒ†ã‚¹ãƒˆ
LlamaãŒã“ã‚Œã‚‰ã®ãƒãƒƒãƒã‚’å‘¼ã³å‡ºã™ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
"""

from llama_cpp import Llama
import json
import random
from datetime import datetime, timedelta

class Batch2NumericalAnalyzer:
    """ãƒãƒƒãƒ2: æ•°å€¤ãƒ‡ãƒ¼ã‚¿åˆ†æAI"""
    
    def analyze_productivity(self, location_id: int, date_range: dict):
        """ç”Ÿç”£æ€§åˆ†æï¼ˆãƒ€ãƒŸãƒ¼å®Ÿè£…ï¼‰"""
        # å®Ÿéš›ã¯DBã‹ã‚‰å–å¾—
        dummy_data = {
            1: {"name": "æœ­å¹Œ", "productivity": 95, "trend": "stable"},
            2: {"name": "ç››å²¡", "productivity": 110, "trend": "increasing"},
            3: {"name": "æ¨ªæµœ", "productivity": 85, "trend": "decreasing"},
            4: {"name": "äº¬éƒ½", "productivity": 100, "trend": "stable"}
        }
        
        location_data = dummy_data.get(location_id, {})
        
        return {
            "location_id": location_id,
            "location_name": location_data.get("name", "ä¸æ˜"),
            "productivity_rate": location_data.get("productivity", 0),
            "trend": location_data.get("trend", "unknown"),
            "analysis": f"{location_data.get('name', 'ä¸æ˜')}æ‹ ç‚¹ã®ç”Ÿç”£æ€§ã¯{location_data.get('productivity', 0)}%ã§ã™ã€‚",
            "recommendation": "ç†Ÿç·´è€…ã®è¿½åŠ é…ç½®ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚" if location_data.get("productivity", 100) < 90 else "ç¾çŠ¶ç¶­æŒã§å•é¡Œã‚ã‚Šã¾ã›ã‚“ã€‚"
        }
    
    def forecast_workload(self, date: str):
        """æ¥­å‹™é‡äºˆæ¸¬ï¼ˆãƒ€ãƒŸãƒ¼å®Ÿè£…ï¼‰"""
        # å®Ÿéš›ã¯éå»ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰äºˆæ¸¬
        base_workload = 100
        random_factor = random.uniform(0.8, 1.5)
        
        return {
            "date": date,
            "predicted_workload": int(base_workload * random_factor),
            "confidence": random.uniform(0.7, 0.95),
            "factors": ["éå»ã®å‚¾å‘", "æ›œæ—¥ãƒ‘ã‚¿ãƒ¼ãƒ³", "å­£ç¯€è¦å› "]
        }

class Batch3KnowledgeOptimizer:
    """ãƒãƒƒãƒ3: ãƒã‚¦ãƒã‚¦ãƒ™ãƒ¼ã‚¹æœ€é©åŒ–AI"""
    
    def get_employee_preferences(self, employee_id: str):
        """å¾“æ¥­å“¡ã®ç‰¹æ€§ãƒ»å¥½ã¿ï¼ˆãƒ€ãƒŸãƒ¼å®Ÿè£…ï¼‰"""
        # å®Ÿéš›ã¯RAGã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å–å¾—
        preferences = {
            "E001": {
                "name": "ç”°ä¸­",
                "morning_performance": "low",
                "preferred_tasks": ["å“è³ªãƒã‚§ãƒƒã‚¯", "ãƒ‡ãƒ¼ã‚¿ç¢ºèª"],
                "notes": "æœˆæ›œæœã¯èª¿å­ãŒæ‚ªã„"
            },
            "E002": {
                "name": "ä½è—¤",
                "morning_performance": "high",
                "preferred_tasks": ["ãƒ‡ãƒ¼ã‚¿å…¥åŠ›", "è£œæ­£å‡¦ç†"],
                "notes": "æœä¸€ç•ªãŒæœ€ã‚‚ç”Ÿç”£çš„"
            }
        }
        
        return preferences.get(employee_id, {
            "name": "ä¸æ˜",
            "morning_performance": "normal",
            "preferred_tasks": [],
            "notes": "ç‰¹è¨˜äº‹é …ãªã—"
        })
    
    def optimize_assignment(self, employees: list, tasks: list, constraints: dict):
        """æœ€é©é…ç½®ã®ææ¡ˆï¼ˆãƒ€ãƒŸãƒ¼å®Ÿè£…ï¼‰"""
        # å®Ÿéš›ã¯è¤‡é›‘ãªæœ€é©åŒ–ãƒ­ã‚¸ãƒƒã‚¯
        assignments = []
        
        for i, emp in enumerate(employees):
            task = tasks[i % len(tasks)]
            pref = self.get_employee_preferences(emp)
            
            assignments.append({
                "employee_id": emp,
                "employee_name": pref["name"],
                "assigned_task": task,
                "shift_time": "åˆå¾Œ" if pref["morning_performance"] == "low" else "åˆå‰",
                "confidence": random.uniform(0.8, 0.95)
            })
        
        return {
            "assignments": assignments,
            "optimization_score": random.uniform(0.85, 0.95),
            "applied_rules": ["å¾“æ¥­å“¡ã®å¥½ã¿è€ƒæ…®", "ã‚¹ã‚­ãƒ«ãƒãƒƒãƒãƒ³ã‚°", "è² è·åˆ†æ•£"]
        }

class AIOrchestrator:
    """ãƒ¡ã‚¤ãƒ³AIï¼ˆLlamaï¼‰ãŒãƒãƒƒãƒã‚’çµ±åˆçš„ã«åˆ¶å¾¡"""
    
    def __init__(self, model_path):
        print("ğŸ¤– AIã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’åˆæœŸåŒ–ä¸­...")
        
        self.llm = Llama(
            model_path=model_path,
            n_ctx=2048,
            n_threads=8,
            n_gpu_layers=1,
        )
        
        self.batch2 = Batch2NumericalAnalyzer()
        self.batch3 = Batch3KnowledgeOptimizer()
        
        print("âœ… åˆæœŸåŒ–å®Œäº†ï¼\n")
    
    def process_request(self, user_query: str):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†"""
        print(f"ğŸ‘¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼: {user_query}\n")
        
        # Step 1: LlamaãŒå¿…è¦ãªãƒãƒƒãƒã‚’åˆ¤æ–­
        analysis_prompt = f"""<s>[INST] <<SYS>>
ã‚ãªãŸã¯åŠ´åƒåŠ›ç®¡ç†AIã§ã™ã€‚ä»¥ä¸‹ã®ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã§ãã¾ã™ï¼š
- batch2_analyze_productivity: ç”Ÿç”£æ€§ã‚’æ•°å€¤åˆ†æ
- batch2_forecast_workload: æ¥­å‹™é‡ã‚’äºˆæ¸¬
- batch3_get_preferences: å¾“æ¥­å“¡ã®ç‰¹æ€§ã‚’å–å¾—
- batch3_optimize_assignment: æœ€é©é…ç½®ã‚’è¨ˆç®—

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã«å¿…è¦ãªãƒ„ãƒ¼ãƒ«ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚
<</SYS>>

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {user_query}

å¿…è¦ãªãƒ„ãƒ¼ãƒ«ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰: [/INST]"""
        
        # ä»Šå›ã¯ãƒ‡ãƒ¢ãªã®ã§å›ºå®šã§ä¸¡æ–¹ã®ãƒãƒƒãƒã‚’ä½¿ç”¨
        print("ğŸ”§ å¿…è¦ãªãƒ„ãƒ¼ãƒ«ã‚’åˆ¤æ–­ä¸­...")
        
        # Step 2: ãƒãƒƒãƒ2ã‚’å®Ÿè¡Œï¼ˆæ•°å€¤åˆ†æï¼‰
        print("\nğŸ“Š ãƒãƒƒãƒ2ï¼ˆæ•°å€¤åˆ†æï¼‰ã‚’å®Ÿè¡Œä¸­...")
        productivity_data = self.batch2.analyze_productivity(3, {})  # æ¨ªæµœæ‹ ç‚¹
        workload_data = self.batch2.forecast_workload("2024-11-20")
        
        print(f"  ç”Ÿç”£æ€§: {productivity_data['productivity_rate']}%")
        print(f"  äºˆæ¸¬æ¥­å‹™é‡: {workload_data['predicted_workload']}%")
        
        # Step 3: ãƒãƒƒãƒ3ã‚’å®Ÿè¡Œï¼ˆãƒã‚¦ãƒã‚¦åˆ†æï¼‰
        print("\nğŸ§  ãƒãƒƒãƒ3ï¼ˆãƒã‚¦ãƒã‚¦åˆ†æï¼‰ã‚’å®Ÿè¡Œä¸­...")
        optimization_data = self.batch3.optimize_assignment(
            ["E001", "E002", "E003"],
            ["ãƒ‡ãƒ¼ã‚¿å…¥åŠ›", "å“è³ªãƒã‚§ãƒƒã‚¯", "è£œæ­£å‡¦ç†"],
            {}
        )
        
        print(f"  æœ€é©åŒ–ã‚¹ã‚³ã‚¢: {optimization_data['optimization_score']:.2%}")
        
        # Step 4: LlamaãŒçµ±åˆçš„ãªå›ç­”ã‚’ç”Ÿæˆ
        print("\nğŸ’­ çµ±åˆçš„ãªå›ç­”ã‚’ç”Ÿæˆä¸­...")
        
        final_prompt = f"""<s>[INST] <<SYS>>
ã‚ãªãŸã¯åŠ´åƒåŠ›ç®¡ç†AIã§ã™ã€‚ä»¥ä¸‹ã®åˆ†æçµæœã‚’åŸºã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚
<</SYS>>

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {user_query}

åˆ†æçµæœ:
1. ç”Ÿç”£æ€§åˆ†æ: {json.dumps(productivity_data, ensure_ascii=False, indent=2)}
2. æ¥­å‹™é‡äºˆæ¸¬: {json.dumps(workload_data, ensure_ascii=False, indent=2)}
3. æœ€é©é…ç½®: {json.dumps(optimization_data, ensure_ascii=False, indent=2)}

ã“ã‚Œã‚‰ã®çµæœã‚’çµ±åˆã—ã¦ã€å…·ä½“çš„ãªææ¡ˆã‚’å«ã‚€å›ç­”ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„: [/INST]"""
        
        response = self.llm(final_prompt, max_tokens=500)
        answer = response['choices'][0]['text'].strip()
        
        print(f"\nğŸ¤– AI: {answer}\n")
        
        return {
            "user_query": user_query,
            "batch2_results": {
                "productivity": productivity_data,
                "workload": workload_data
            },
            "batch3_results": {
                "optimization": optimization_data
            },
            "final_answer": answer
        }

def main():
    orchestrator = AIOrchestrator("./models/llama-2-7b-chat.Q4_K_M.gguf")
    
    print("=" * 60)
    print("ğŸš€ ãƒãƒƒãƒçµ±åˆãƒ†ã‚¹ãƒˆã‚’é–‹å§‹ã—ã¾ã™")
    print("=" * 60)
    
    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
    test_queries = [
        "æ¨ªæµœæ‹ ç‚¹ã®æ˜æ—¥ã®äººå“¡é…ç½®ã‚’æœ€é©åŒ–ã—ã¦ãã ã•ã„",
        "ç”Ÿç”£æ€§ãŒä½ä¸‹ã—ã¦ã„ã‚‹æ‹ ç‚¹ã¸ã®å¯¾ç­–ã‚’ææ¡ˆã—ã¦ãã ã•ã„",
        "æœˆæ›œæ—¥ã®æœã®é…ç½®ã§æ³¨æ„ã™ã¹ãç‚¹ã‚’æ•™ãˆã¦ãã ã•ã„"
    ]
    
    for i, query in enumerate(test_queries, 1):
        print(f"\nã€ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ {i}ã€‘")
        print("-" * 60)
        
        result = orchestrator.process_request(query)
        
        print("\nğŸ“‹ å®Ÿè¡Œã‚µãƒãƒªãƒ¼:")
        print(f"  - ãƒãƒƒãƒ2å®Ÿè¡Œ: âœ…")
        print(f"  - ãƒãƒƒãƒ3å®Ÿè¡Œ: âœ…")
        print(f"  - çµ±åˆå›ç­”ç”Ÿæˆ: âœ…")
        print("=" * 60)

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")