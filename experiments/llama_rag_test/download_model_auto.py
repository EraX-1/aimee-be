#!/usr/bin/env python3
"""
Llamaãƒ¢ãƒ‡ãƒ«ã®è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
M3 Macç”¨ã«æœ€é©åŒ–ã•ã‚ŒãŸé‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
"""

import os
import sys
import requests
from pathlib import Path

def download_file(url, filename):
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹é–¢æ•°ï¼ˆãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ä»˜ãï¼‰"""
    print(f"ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹: {filename}")
    
    response = requests.get(url, stream=True)
    total_size = int(response.headers.get('content-length', 0))
    
    downloaded = 0
    chunk_size = 8192
    
    with open(filename, 'wb') as file:
        for chunk in response.iter_content(chunk_size=chunk_size):
            if chunk:
                file.write(chunk)
                downloaded += len(chunk)
                
                # ç°¡æ˜“ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹è¡¨ç¤º
                if total_size > 0:
                    progress = (downloaded / total_size) * 100
                    print(f"\ré€²è¡ŒçŠ¶æ³: {progress:.1f}% ({downloaded / 1024 / 1024:.1f}MB / {total_size / 1024 / 1024:.1f}MB)", end='', flush=True)
    
    print()  # æ”¹è¡Œ

def main():
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã§ãƒ¢ãƒ‡ãƒ«é¸æŠï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯1ï¼‰
    model_choice = sys.argv[1] if len(sys.argv) > 1 else "1"
    
    models_dir = Path("models")
    models_dir.mkdir(exist_ok=True)
    
    # ãƒ¢ãƒ‡ãƒ«ã®å®šç¾©
    models = {
        "1": {
            "name": "Llama-2-7B-Chat-GGUF (Q4_K_M)",
            "url": "https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/resolve/main/llama-2-7b-chat.Q4_K_M.gguf",
            "filename": "llama-2-7b-chat.Q4_K_M.gguf",
            "size": "4.08GB",
            "description": "æ¨™æº–çš„ãª7Bãƒ¢ãƒ‡ãƒ«ï¼ˆæ¨å¥¨ï¼‰"
        },
        "2": {
            "name": "Llama-2-7B-Chat-GGUF (Q3_K_S)",
            "url": "https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/resolve/main/llama-2-7b-chat.Q3_K_S.gguf",
            "filename": "llama-2-7b-chat.Q3_K_S.gguf",
            "size": "2.95GB",
            "description": "ã‚ˆã‚Šè»½é‡ãª7Bãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ¡ãƒ¢ãƒªç¯€ç´„ï¼‰"
        }
    }
    
    if model_choice not in models:
        print(f"âŒ ç„¡åŠ¹ãªé¸æŠ: {model_choice}")
        print("ä½¿ç”¨æ–¹æ³•: python download_model_auto.py [1|2]")
        return
    
    model = models[model_choice]
    filepath = models_dir / model['filename']
    
    # æ—¢ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã‹ãƒã‚§ãƒƒã‚¯
    if filepath.exists():
        print(f"âœ… {model['name']} ã¯æ—¢ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã§ã™")
        print(f"ğŸ“ ãƒ‘ã‚¹: {filepath}")
        return
    
    print(f"\nğŸ“¦ {model['name']} ({model['size']}) ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™")
    print(f"ğŸ“ èª¬æ˜: {model['description']}")
    print(f"ğŸ“ ä¿å­˜å…ˆ: {filepath}\n")
    
    try:
        download_file(model['url'], str(filepath))
        print(f"\nâœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†ï¼")
        print(f"ğŸ“ ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹: {filepath}")
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—æ™‚ã¯éƒ¨åˆ†ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        if filepath.exists():
            filepath.unlink()

if __name__ == "__main__":
    main()